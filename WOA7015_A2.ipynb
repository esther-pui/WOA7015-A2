{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/esther-pui/WOA7015-A2/blob/main/WOA7015_A2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Logistic regression from scratch**"
      ],
      "metadata": {
        "id": "T03bZ6L_oW_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "train_data = np.loadtxt('/Train_toydata.txt')\n",
        "test_data = np.loadtxt('/Test_toydata.txt')\n",
        "\n",
        "x_features = train_data[:, :-1]\n",
        "y_class = train_data[:, -1].reshape(-1, 1)\n",
        "\n",
        "m = x_features.shape[0]\n",
        "bias_col = np.ones((m, 1))\n",
        "\n",
        "# n x 3 matrix, Bias + Features\n",
        "x_train_augmented = np.hstack((bias_col, x_features))\n",
        "\n",
        "def sigmoid(z):\n",
        "  return 1 / (1 + np.exp(-z))\n"
      ],
      "metadata": {
        "id": "E3GO6K5fL0PS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Function 1**"
      ],
      "metadata": {
        "id": "i0rtxpplRiEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def CalcObj(XTrain, YTrain, wHat):\n",
        "\n",
        "  n_size = XTrain.shape[0]\n",
        "\n",
        "  # weight + bias\n",
        "  z = np.dot(XTrain, wHat)\n",
        "  g = sigmoid(z)\n",
        "  g_clipped = np.clip(g, 1e-15, 1 - 1e-15)\n",
        "\n",
        "  #class 1\n",
        "  term1 = np.multiply(YTrain, np.log(g_clipped))\n",
        "\n",
        "  #class 0\n",
        "  term2 = np.multiply(1 - YTrain, np.log(1 - g_clipped))\n",
        "  obj = -(1 / n_size) * np.sum(term1 + term2)\n",
        "\n",
        "  return obj"
      ],
      "metadata": {
        "id": "loKFCjxNRnsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Function 2**"
      ],
      "metadata": {
        "id": "Z9uwcoegUtnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def CalcGrad(XTrain, YTrain, wHat):\n",
        "\n",
        "  n_size = XTrain.shape[0]\n",
        "  z = np.dot(XTrain, wHat)\n",
        "  h_sigmoid = sigmoid(z)\n",
        "\n",
        "  # difference between true vector and prediction\n",
        "  Y_error_vector = h_sigmoid - YTrain\n",
        "\n",
        "  # matrix multiplication\n",
        "  grad = np.dot(XTrain.T, Y_error_vector) / n_size\n",
        "\n",
        "  return grad"
      ],
      "metadata": {
        "id": "YOwywXfdUy37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Function 3**"
      ],
      "metadata": {
        "id": "nryWpjasY52l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def UpdateParams(weight, grad, lr):\n",
        "  new_w = weight - (lr * grad)\n",
        "  return new_w"
      ],
      "metadata": {
        "id": "jcDBiLqXY9Vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Function 4**"
      ],
      "metadata": {
        "id": "gcnTn7WSZigC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def CheckConvg(oldObj, newObj, tol):\n",
        "  has_converged = np.abs(oldObj - newObj) < tol\n",
        "  return has_converged"
      ],
      "metadata": {
        "id": "ENO2BIFoZlne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Function 5**"
      ],
      "metadata": {
        "id": "xxG0qLzcaVyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LR = 0.01\n",
        "TOL = 0.001\n",
        "\n",
        "def GradientDescent(XTrain, YTrain):\n",
        "\n",
        "  parameter_size = XTrain.shape[1]\n",
        "  # starting weight & bias\n",
        "  wHat = np.zeros((parameter_size, 1))\n",
        "\n",
        "  objVals = []\n",
        "  converged = False\n",
        "\n",
        "  # initial loss, store scalar for comparison\n",
        "  current_loss_scalar = CalcObj(XTrain, YTrain, wHat).item()\n",
        "  objVals.append(current_loss_scalar)\n",
        "\n",
        "  i = 0\n",
        "\n",
        "  while not converged:\n",
        "    old_loss_scalar = current_loss_scalar\n",
        "\n",
        "    #training\n",
        "    grad = CalcGrad(XTrain, YTrain, wHat)\n",
        "    wHat = UpdateParams(wHat, grad, LR)\n",
        "\n",
        "    #calculate new loss\n",
        "    new_loss_scalar = CalcObj(XTrain, YTrain, wHat).item()\n",
        "    objVals.append(new_loss_scalar)\n",
        "\n",
        "    #check converge\n",
        "    converged = CheckConvg(old_loss_scalar, new_loss_scalar, TOL)\n",
        "    current_loss_scalar = new_loss_scalar\n",
        "    i += 1\n",
        "\n",
        "  return wHat, objVals\n"
      ],
      "metadata": {
        "id": "ZYxH1apyaeJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training**"
      ],
      "metadata": {
        "id": "-tOAnNTCgS58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_wHat, loss_history = GradientDescent(x_train_augmented, y_class)"
      ],
      "metadata": {
        "id": "fixJQtnUgUYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Function 6**"
      ],
      "metadata": {
        "id": "G1-KqnDgcQoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def PredictLabels (XTest, YTest, wHat):\n",
        "\n",
        "  # forward pass 1\n",
        "  z = np.dot(XTest, wHat)\n",
        "\n",
        "  # forward pass 2\n",
        "  h = sigmoid(z)\n",
        "\n",
        "  # classification\n",
        "  yHat = np.where(h >= 0.5, 1, 0)\n",
        "\n",
        "  # error count\n",
        "  misclassified_idx = np.where(np.not_equal(yHat, YTest))[0]\n",
        "  numErrors = len(misclassified_idx)\n",
        "\n",
        "  if numErrors > 0:\n",
        "    first_error_idx = misclassified_idx[0]\n",
        "    predicted_val = yHat[first_error_idx, 0]\n",
        "    actual_val = YTest[first_error_idx, 0]\n",
        "\n",
        "    print(\"\\nMisclassified samples:\")\n",
        "    print(f\"Index: {first_error_idx}, Predicted: {predicted_val}, Actual: {actual_val}\")\n",
        "\n",
        "  return yHat, numErrors\n"
      ],
      "metadata": {
        "id": "O9YJH8j3cOpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Predict**"
      ],
      "metadata": {
        "id": "5GX3GgYPnWLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_features = test_data[:, :-1]\n",
        "y_test_class = test_data[:, -1].reshape(-1, 1)\n",
        "\n",
        "# add Bias Term\n",
        "m_test = x_test_features.shape[0]\n",
        "bias_col_test = np.ones((m_test, 1))\n",
        "x_test_augmented = np.hstack((bias_col_test, x_test_features))\n",
        "\n",
        "yHat, numErrors = PredictLabels(x_test_augmented, y_test_class, final_wHat)\n",
        "\n",
        "# get accuracy\n",
        "total_samples = y_test_class.shape[0]\n",
        "accuracy_scratch = (total_samples - numErrors) / total_samples\n",
        "\n",
        "print(\"\\n---- Scratch result ----\")\n",
        "print(f\"Total test samples: {total_samples}\")\n",
        "print(f\"Total misclassified errors: {numErrors}\")\n",
        "print(f\"Accuracy: {accuracy_scratch * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uElCM0zfnX23",
        "outputId": "295d5604-6faa-4d85-8e02-b407d05785e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Misclassified samples:\n",
            "Index: 2, Predicted: 1, Actual: 0.0\n",
            "\n",
            "---- Scratch result ----\n",
            "Total test samples: 20\n",
            "Total misclassified errors: 1\n",
            "Accuracy: 95.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Logistic regression using PyTorch**"
      ],
      "metadata": {
        "id": "HtqnCzdSpgN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# convert to tensor\n",
        "def to_tensor(x, y):\n",
        "    x_tensor = torch.tensor(x, dtype=torch.float32)\n",
        "    y_tensor = torch.tensor(y, dtype=torch.float32)\n",
        "    return x_tensor, y_tensor\n",
        "\n",
        "x_train_tensor, y_train_tensor = to_tensor(x_train_augmented, y_class)\n",
        "x_test_tensor, y_test_tensor = to_tensor(x_test_augmented, y_test_class)\n",
        "\n",
        "# model class\n",
        "class LogisticRegression(nn.Module):\n",
        "  def __init__(self, input_size):\n",
        "    super(LogisticRegression, self).__init__()\n",
        "\n",
        "    # initiate parameter\n",
        "    self.linear = nn.Linear(input_size, 1, bias=False)\n",
        "\n",
        "  # get prediction outputs\n",
        "  def forward(self, x):\n",
        "    return self.linear(x)\n",
        "\n",
        "model = LogisticRegression(input_size=x_train_augmented.shape[1])\n",
        "\n",
        "# GradientDescent\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01) #same lr as task 1\n",
        "\n",
        "# CalcObj\n",
        "loss_function = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# training loop\n",
        "num_epochs = 5000\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "  # run forward\n",
        "  outputs = model(x_train_tensor)\n",
        "  loss = loss_function(outputs, y_train_tensor)\n",
        "\n",
        "  # reset\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # CalcGrad\n",
        "  loss.backward()\n",
        "\n",
        "  # UpdateParams\n",
        "  optimizer.step()\n",
        "\n",
        "# testing and get acuracy\n",
        "with torch.no_grad(): # no gradient\n",
        "  outputs = model(x_test_tensor)\n",
        "  predicted_probs = torch.sigmoid(outputs)\n",
        "  y_predicted_tensor = (predicted_probs >= 0.5).float()\n",
        "\n",
        "  total_samples_pytorch = y_test_tensor.size(0)\n",
        "  numErrors_pytorch = (y_predicted_tensor != y_test_tensor).sum().item()\n",
        "  accuracy_pytorch = (total_samples_pytorch - numErrors_pytorch) / total_samples_pytorch\n",
        "\n",
        "# result\n",
        "print(\"\\n---- PyTorch result ----\")\n",
        "print(f\"Total test samples: {total_samples_pytorch}\")\n",
        "print(f\"Total misclassified errors: {numErrors_pytorch}\")\n",
        "print(f\"Accuracy: {accuracy_pytorch * 100:.2f}%\")\n",
        "\n",
        "# find misclassified samples\n",
        "misclassified_indices_pytorch = (y_predicted_tensor != y_test_tensor).nonzero(as_tuple=True)[0]\n",
        "\n",
        "print(\"\\nMisclassified samples:\")\n",
        "for idx in misclassified_indices_pytorch:\n",
        "    print(f\"Index: {idx.item()}, Predicted: {y_predicted_tensor[idx].item()}, Actual: {y_test_tensor[idx].item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZW5NFxNosEe",
        "outputId": "0970db38-757e-4be2-df19-8ec4392350cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---- PyTorch result ----\n",
            "Total test samples: 20\n",
            "Total misclassified errors: 1\n",
            "Accuracy: 95.00%\n",
            "\n",
            "Misclassified samples:\n",
            "Index: 2, Predicted: 1.0, Actual: 0.0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1GDAx9FQPkyZux-slq7Gx2_pbp_BuzKKq",
      "authorship_tag": "ABX9TyNcJdwRzDD4gg3ZIV3YGiR/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}